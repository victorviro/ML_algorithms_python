{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hyperopt Hyperparameter Optimization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNVqe70Jgs5XxYNezEHHnJD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victorviro/Machine-Learning-Python/blob/master/Hyperopt_Hyperparameter_Optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "641eiG5NPcuW"
      },
      "source": [
        "# Parameter optimization with hyperopt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXTw72fG9Fp9"
      },
      "source": [
        "[Hyperopt](https://github.com/hyperopt/hyperopt) is a Python library for serial and parallel optimization over awkward search spaces, which may include real-valued, discrete, and conditional dimensions.\n",
        "\n",
        "It is designed for large-scale optimization for models with hundreds of parameters and allows the optimization procedure to be scaled across multiple cores and multiple machines.\n",
        "\n",
        "The library was explicitly used to optimize machine learning pipelines, including data preparation, model selection, and model hyperparameters.\n",
        "\n",
        "Let's see how to find the best model and parameters for classifying the [Housing dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html) using this library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B229J39gADXT"
      },
      "source": [
        "## Prepare the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-skCdTIc-NdW",
        "outputId": "4b5cfc45-e752-44a6-ec1c-dc26c8fe1ce3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "from sklearn.datasets import load_boston\n",
        "import pandas as pd\n",
        "X, y = load_boston(return_X_y=True)\n",
        "X = pd.DataFrame(X)\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "X.head()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(506, 13)\n",
            "(506,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1.0</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        0     1     2    3      4   ...   8      9     10      11    12\n",
              "0  0.00632  18.0  2.31  0.0  0.538  ...  1.0  296.0  15.3  396.90  4.98\n",
              "1  0.02731   0.0  7.07  0.0  0.469  ...  2.0  242.0  17.8  396.90  9.14\n",
              "2  0.02729   0.0  7.07  0.0  0.469  ...  2.0  242.0  17.8  392.83  4.03\n",
              "3  0.03237   0.0  2.18  0.0  0.458  ...  3.0  222.0  18.7  394.63  2.94\n",
              "4  0.06905   0.0  2.18  0.0  0.458  ...  3.0  222.0  18.7  396.90  5.33\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4IERwot_3Io"
      },
      "source": [
        "We split the data into into training and test sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxOVqez0_YWN"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LEJil91_1Ek"
      },
      "source": [
        "## Define a function to minimize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YK6aNCOLAFxC"
      },
      "source": [
        "In this example, we want to search for a regression linear model. We define a parameter `params['type']` as the model name. We define a function to run the training and return the mean squared error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRyak4hnK27U"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jp-xqWUMAP-2"
      },
      "source": [
        "def objective(params):\n",
        "    regressors_type = params['type']\n",
        "    del params['type']\n",
        "    if regressors_type == 'ElasticNet':\n",
        "        pipe = Pipeline([('scaler', StandardScaler()),\n",
        "                         ('ElasticNet', ElasticNet(**params))])\n",
        "        pipe.fit(X_train, y_train)\n",
        "        y_pred_test = pipe.predict(X_test)\n",
        "    else:\n",
        "        return 0    \n",
        "    loss = mean_squared_error(y_test, y_pred_test)\n",
        "    \n",
        "    return {'loss': loss, 'status': STATUS_OK}"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J5PnHa8OhZw"
      },
      "source": [
        "## Define the search space over hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtlLFrHVOmWa"
      },
      "source": [
        "See the [Hyperopt docs](https://github.com/hyperopt/hyperopt/wiki/FMin#21-parameter-expressions) for details on defining a search space and parameter expressions.\n",
        "\n",
        "Use `hp.choice` to select different models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7S3RmW7pLfAV"
      },
      "source": [
        "search_space = hp.choice('regressor_type', [\n",
        "    {\n",
        "        'type': 'ElasticNet',\n",
        "        'alpha': hp.lognormal('alpha', 0, 1.0),\n",
        "        'l1_ratio': hp.lognormal('l1_ratio', 0, 1.0)\n",
        "    },\n",
        "])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYd4WOsHOtLC"
      },
      "source": [
        "## Select a search algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqnC4I0ZOuPa"
      },
      "source": [
        "The two main choices are:\n",
        "\n",
        "- `hyperopt.tpe.suggest`: Tree of Parzen Estimators, a Bayesian approach which iteratively and adaptively selects new hyperparameter settings to explore based on past results.\n",
        "\n",
        "- `hyperopt.rand.suggest`: Random search, a non-adaptive approach which samples over the search space.\n",
        "\n",
        "See [Algorithms for Hyper-Parameter Optimization](https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0neKswgO-UL"
      },
      "source": [
        "algorithm = tpe.suggest"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCw423ngO8Ps"
      },
      "source": [
        "## Run the tuning algorithm with hyperopt `fmin()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZ09g1sDPHdQ"
      },
      "source": [
        "Set `max_evals` to the maximum number of points in hyperparameter space to test, that is, the maximum number of models to fit and evaluate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCLoPKjRLurT",
        "outputId": "69473f9d-fc07-4a29-daac-a18c465e379a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "best_result = fmin(\n",
        "    fn=objective, \n",
        "    space=search_space,\n",
        "    algo=algorithm,\n",
        "    max_evals=16)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:00<00:00, 140.01it/s, best loss: 24.374209595650548]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 2.795024589970502\n",
            "  positive)\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 2.795024589970502\n",
            "  positive)\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 2.795024589970502\n",
            "  positive)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvmDH-yhL0VV",
        "outputId": "e3d65576-0580-4dd7-943e-b28265fa5360",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(f'best parameters: {best_result}')"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best parameters: {'alpha': 0.2807037574860731, 'l1_ratio': 1.510527308817968, 'regressor_type': 0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIPdgG21Sv1h"
      },
      "source": [
        "**Note**: Our results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision. Consider running the example a few times."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRs5-dOrQzMu"
      },
      "source": [
        "## Hyperparameter Optimization with hyperopt-sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5d_0rG6Q5qr"
      },
      "source": [
        "[Hyperopt-sklearn](https://github.com/hyperopt/hyperopt-sklearn) is Hyperopt-based model selection among machine learning algorithms in scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkTQSNt-RffE",
        "outputId": "6289baf2-a4b3-460a-e819-651c3706f3c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        }
      },
      "source": [
        "!pip install git+https://github.com/hyperopt/hyperopt-sklearn.git"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/hyperopt/hyperopt-sklearn.git\n",
            "  Cloning https://github.com/hyperopt/hyperopt-sklearn.git to /tmp/pip-req-build-ak4msr39\n",
            "  Running command git clone -q https://github.com/hyperopt/hyperopt-sklearn.git /tmp/pip-req-build-ak4msr39\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.6/dist-packages (from hpsklearn==0.0.3) (0.1.2)\n",
            "Collecting nose\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from hpsklearn==0.0.3) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from hpsklearn==0.0.3) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hpsklearn==0.0.3) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt->hpsklearn==0.0.3) (2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt->hpsklearn==0.0.3) (1.15.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt->hpsklearn==0.0.3) (3.11.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from hyperopt->hpsklearn==0.0.3) (4.41.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt->hpsklearn==0.0.3) (0.16.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->hpsklearn==0.0.3) (0.16.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt->hpsklearn==0.0.3) (4.4.2)\n",
            "Building wheels for collected packages: hpsklearn\n",
            "  Building wheel for hpsklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hpsklearn: filename=hpsklearn-0.0.3-cp36-none-any.whl size=26799 sha256=3e44c7132a8731abe8a43fb7c0b0992cba9cfaf829684dd566ba5e9bd0e4bb9c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6hl448ha/wheels/28/93/20/67dca95c2aaa13466b4900ba79a7bab66022e50ce44f8a438d\n",
            "Successfully built hpsklearn\n",
            "Installing collected packages: nose, hpsklearn\n",
            "Successfully installed hpsklearn-0.0.3 nose-1.3.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwUXvd97Rcny",
        "outputId": "e5ed0a33-6425-41f9-a80a-96260a0be573",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from hpsklearn import HyperoptEstimator\n",
        "from hpsklearn import any_regressor\n",
        "from hpsklearn import any_preprocessing\n",
        "from hyperopt import tpe\n",
        "\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARN: OMP_NUM_THREADS=None =>\n",
            "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzW5hEwWR4oS"
      },
      "source": [
        "We define the search procedure. We will explore all regressor algorithms and all data transforms available to the library and use the Tree of Parzen Estimators search algorithm.\n",
        "\n",
        "The search will evaluate 50 pipelines and limit each evaluation to 30 seconds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6o1Gh28RaWi"
      },
      "source": [
        "# define search\n",
        "hyperopt_estimator = HyperoptEstimator(regressor=any_regressor('reg'),\n",
        "                          preprocessing=any_preprocessing('pre'),\n",
        "                          loss_fn=mean_squared_error,\n",
        "                          algo=tpe.suggest, max_evals=50, trial_timeout=30)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtc0bOFDSgnh"
      },
      "source": [
        "We then start the search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2RM6BFPShdJ",
        "outputId": "7e8566b4-a6f9-475e-e6f4-041c43aa4bec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "hyperopt_estimator.fit(X_train, y_train)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.48it/s, best loss: 55.61112402065533]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_gb.py:1342: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
            "  FutureWarning)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  7.09it/s, best loss: 19.292188821582922]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.96it/s, best loss: 19.292188821582922]\n",
            "100%|██████████| 1/1 [00:00<00:00,  8.83it/s, best loss: 19.292188821582922]\n",
            "[18:36:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.18s/it, best loss: 19.292188821582922]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.05it/s, best loss: 19.292188821582922]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.08it/s, best loss: 19.292188821582922]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.19it/s, best loss: 19.292188821582922]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.40it/s, best loss: 19.18266657314485]\n",
            "100%|██████████| 1/1 [00:00<00:00,  7.54it/s, best loss: 19.18266657314485]\n",
            "[18:36:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.47s/it, best loss: 12.616274214690932]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.98s/it, best loss: 12.616274214690932]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.38s/it, best loss: 12.616274214690932]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.51s/it, best loss: 12.616274214690932]\n",
            "[18:36:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.06s/it, best loss: 12.616274214690932]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.14it/s, best loss: 12.616274214690932]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.34it/s, best loss: 12.616274214690932]\n",
            "100%|██████████| 1/1 [00:00<00:00,  7.67it/s, best loss: 12.616274214690932]\n",
            "100%|██████████| 1/1 [00:00<00:00, 11.58it/s, best loss: 12.616274214690932]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.04it/s, best loss: 12.616274214690932]\n",
            "100%|██████████| 1/1 [00:03<00:00,  3.25s/it, best loss: 12.616274214690932]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.33it/s, best loss: 12.616274214690932]\n",
            "[18:36:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.02it/s, best loss: 12.616274214690932]\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.04it/s, best loss: 12.616274214690932]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_gb.py:1342: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
            "  FutureWarning)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.63s/it, best loss: 12.616274214690932]\n",
            "100%|██████████| 1/1 [00:03<00:00,  3.41s/it, best loss: 12.616274214690932]\n",
            "[18:36:34] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.68it/s, best loss: 12.616274214690932]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.06it/s, best loss: 12.616274214690932]\n",
            "[18:36:35] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.32it/s, best loss: 12.616274214690932]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_gb.py:1342: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
            "  FutureWarning)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  4.79it/s, best loss: 12.616274214690932]\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.36it/s, best loss: 12.616274214690932]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.74s/it, best loss: 12.616274214690932]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.07it/s, best loss: 12.616274214690932]\n",
            "[18:36:39] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.43s/it, best loss: 11.032993002355472]\n",
            "[18:36:40] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.43s/it, best loss: 10.589484419204354]\n",
            "[18:36:42] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.06s/it, best loss: 10.440331595617312]\n",
            "[18:36:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.22it/s, best loss: 10.440331595617312]\n",
            "[18:36:44] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.06it/s, best loss: 9.510321254226078]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_gb.py:1342: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
            "  FutureWarning)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:02<00:00,  2.01s/it, best loss: 9.510321254226078]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.45it/s, best loss: 9.510321254226078]\n",
            "[18:36:47] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.68it/s, best loss: 9.510321254226078]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.67it/s, best loss: 9.510321254226078]\n",
            "[18:36:49] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.70it/s, best loss: 9.510321254226078]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.25it/s, best loss: 9.510321254226078]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.75it/s, best loss: 9.510321254226078]\n",
            "[18:36:50] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.05it/s, best loss: 9.510321254226078]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.69it/s, best loss: 9.510321254226078]\n",
            "[18:36:51] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.51it/s, best loss: 9.510321254226078]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.84s/it, best loss: 9.510321254226078]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.98it/s, best loss: 9.510321254226078]\n",
            "[18:36:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igjn3hACRZrO"
      },
      "source": [
        "We can report the performance of the model on the holdout dataset and summarize the best performing pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83t-L4gwTEle",
        "outputId": "ce473d2a-5de4-44f4-f1e5-b6f6e1bbe252",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "# summarize performance\n",
        "mse = hyperopt_estimator.score(X_test, y_test)\n",
        "print(\"MSE: %.3f\" % mse)\n",
        "# summarize the best model\n",
        "print(f'Best model: {hyperopt_estimator.best_model()}')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE: 0.886\n",
            "Best model: {'learner': XGBRegressor(base_score=0.5, booster='gbtree',\n",
            "             colsample_bylevel=0.9978248847072497, colsample_bynode=1,\n",
            "             colsample_bytree=0.6129378971302373, gamma=3.0369489070285863e-05,\n",
            "             importance_type='gain', learning_rate=0.0059639879541257025,\n",
            "             max_delta_step=0, max_depth=8, min_child_weight=4, missing=nan,\n",
            "             n_estimators=1800, n_jobs=1, nthread=None, objective='reg:linear',\n",
            "             random_state=0, reg_alpha=0.0004566228110865921,\n",
            "             reg_lambda=2.3939670304952703, scale_pos_weight=1, seed=4,\n",
            "             silent=None, subsample=0.6482508600159675, verbosity=1), 'preprocs': (StandardScaler(copy=True, with_mean=True, with_std=False),), 'ex_preprocs': ()}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mReARVkEQSS8"
      },
      "source": [
        "# References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHzlJfcrQVp_"
      },
      "source": [
        "- [Hyperopt](https://github.com/hyperopt/hyperopt)\n",
        "\n",
        "- [Hyperopt basic tutorial](https://github.com/hyperopt/hyperopt/wiki/FMin)\n",
        "\n",
        "- [Algorithms for Hyper-Parameter Optimization](https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf)\n",
        "\n",
        "- https://docs.databricks.com/_static/notebooks/hyperopt-sklearn-model-selection.html\n",
        "\n",
        "- [Tutorial on hyperopt](https://www.kaggle.com/fanvacoolt/tutorial-on-hyperopt)\n",
        "\n",
        "- [Hyperopt-sklearn](https://github.com/hyperopt/hyperopt-sklearn)\n",
        "\n",
        "- https://machinelearningmastery.com/hyperopt-for-automated-machine-learning-with-scikit-learn/\n",
        "\n",
        "- https://hyperopt.github.io/hyperopt-sklearn/\n",
        "\n",
        "- [Hyperopt-Sklearn](https://www.ml4aad.org/wp-content/uploads/2018/07/automl_book_draft_hyperopt-sklearn.pdf)"
      ]
    }
  ]
}