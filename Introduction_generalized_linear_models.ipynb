{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "Introduction_generalized_linear_models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victorviro/ML_algorithms_python/blob/master/Introduction_generalized_linear_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNPMaIpb4tRz",
        "colab_type": "text"
      },
      "source": [
        "# Introduction to Generalized Linear Models (GLM)\n",
        "\n",
        "We will use a dataset that contains data about houses for practice purposes. We will try to predict the house prices using different linear regression models (the data used and the info of the task can be seen [here](https://github.com/victorviro/House-price-prediction-python)). Finally, we will see the logistic regression model for classification problems.\n",
        "\n",
        "\n",
        "* **3. Data preparation**\n",
        "    * 3.1 Dummy variables\n",
        "    * 3.2 Split dataset\n",
        "    \n",
        "    \n",
        "* **4. Generalized Linear Models**\n",
        "    * 4.1 Introduction\n",
        "    * 4.2 Linear regression\n",
        "    * 4.3 Polynomial regression\n",
        "    * 4.4 Regularized linear models \n",
        "    * 4.5 Robustness regression \n",
        "    * 4.6 Stochastic Gradient Descent\n",
        "    * 4.7 Logistic regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdYUgXfY4tR1",
        "colab_type": "text"
      },
      "source": [
        "We import required libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-cLDzEx4tR3",
        "colab_type": "code",
        "outputId": "a6de6e5f-1b61-425e-ae90-e936091e3344",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, Lasso, LassoCV, Ridge, RidgeCV, ElasticNet, ElasticNetCV, \\\n",
        "                                 SGDRegressor, HuberRegressor, LogisticRegression\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78-MYLLrVYNG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDrVIHYa4tR_",
        "colab_type": "text"
      },
      "source": [
        "## Read data processed "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qtb-fH9S4tSA",
        "colab_type": "code",
        "outputId": "24d70fe7-c754-4d2e-8c23-d207fc4363c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "dataset = pd.read_csv('/content/drive/My Drive/datasets/dataset.csv')\n",
        "dataset.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1456, 80)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqGyhuQ24tSG",
        "colab_type": "code",
        "outputId": "d5a735bb-6cbb-4753-abe0-f743604d6527",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "dataset.head(4)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>LotConfig</th>\n",
              "      <th>LandSlope</th>\n",
              "      <th>Neighborhood</th>\n",
              "      <th>Condition1</th>\n",
              "      <th>Condition2</th>\n",
              "      <th>BldgType</th>\n",
              "      <th>HouseStyle</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>RoofStyle</th>\n",
              "      <th>RoofMatl</th>\n",
              "      <th>Exterior1st</th>\n",
              "      <th>Exterior2nd</th>\n",
              "      <th>MasVnrType</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>ExterQual</th>\n",
              "      <th>ExterCond</th>\n",
              "      <th>Foundation</th>\n",
              "      <th>BsmtQual</th>\n",
              "      <th>BsmtCond</th>\n",
              "      <th>BsmtExposure</th>\n",
              "      <th>BsmtFinType1</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinType2</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>Heating</th>\n",
              "      <th>HeatingQC</th>\n",
              "      <th>CentralAir</th>\n",
              "      <th>Electrical</th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>LowQualFinSF</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>KitchenAbvGr</th>\n",
              "      <th>KitchenQual</th>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <th>Functional</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>FireplaceQu</th>\n",
              "      <th>GarageType</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>GarageFinish</th>\n",
              "      <th>GarageCars</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>GarageQual</th>\n",
              "      <th>GarageCond</th>\n",
              "      <th>PavedDrive</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>None</td>\n",
              "      <td>3</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>2</td>\n",
              "      <td>196.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>PConc</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>706.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>856.0</td>\n",
              "      <td>GasA</td>\n",
              "      <td>5</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>856</td>\n",
              "      <td>854</td>\n",
              "      <td>0</td>\n",
              "      <td>1710</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2003.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>548.0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>12.247699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>None</td>\n",
              "      <td>3</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>FR2</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Veenker</td>\n",
              "      <td>Feedr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>1976</td>\n",
              "      <td>1976</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>978.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>284.0</td>\n",
              "      <td>1262.0</td>\n",
              "      <td>GasA</td>\n",
              "      <td>5</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1262</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1976.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>460.0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>Y</td>\n",
              "      <td>298</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>12.109016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>None</td>\n",
              "      <td>2</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2001</td>\n",
              "      <td>2002</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>2</td>\n",
              "      <td>162.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>PConc</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>486.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>434.0</td>\n",
              "      <td>920.0</td>\n",
              "      <td>GasA</td>\n",
              "      <td>5</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>920</td>\n",
              "      <td>866</td>\n",
              "      <td>0</td>\n",
              "      <td>1786</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2001.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>608.0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>12.317171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>None</td>\n",
              "      <td>2</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>Corner</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Crawfor</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1915</td>\n",
              "      <td>1970</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>Wd Sdng</td>\n",
              "      <td>Wd Shng</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>BrkTil</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>216.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>540.0</td>\n",
              "      <td>756.0</td>\n",
              "      <td>GasA</td>\n",
              "      <td>4</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>961</td>\n",
              "      <td>756</td>\n",
              "      <td>0</td>\n",
              "      <td>1717</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>Detchd</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>642.0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>272</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>11.849405</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  MSSubClass MSZoning  ...  SaleType  SaleCondition  SalePrice\n",
              "0           0          60       RL  ...        WD         Normal  12.247699\n",
              "1           1          20       RL  ...        WD         Normal  12.109016\n",
              "2           2          60       RL  ...        WD         Normal  12.317171\n",
              "3           3          70       RL  ...        WD        Abnorml  11.849405\n",
              "\n",
              "[4 rows x 80 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAaouZmW4tYc",
        "colab_type": "text"
      },
      "source": [
        "# 3. Data preparation\n",
        "\n",
        "## 3.1 Dummy variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7saOaqMV4tYd",
        "colab_type": "text"
      },
      "source": [
        "#### We  convert categorical variables to dummy variables. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "EHQVQtJN4tYd",
        "colab_type": "code",
        "outputId": "886ff9c5-8c63-4819-dd59-ee84a70d93db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "dataset = pd.get_dummies(dataset)\n",
        "print(dataset.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1456, 230)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQhtbwCu4tYh",
        "colab_type": "text"
      },
      "source": [
        "##  3.2 Split dataset in test and train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uih4AS-y4tYh",
        "colab_type": "text"
      },
      "source": [
        "#### We split data in training and testing datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZvnyM6K4tYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(dataset.drop('SalePrice', axis=1),dataset.SalePrice,test_size=0.33,random_state=66)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVkt4gZz4tY3",
        "colab_type": "text"
      },
      "source": [
        "#  4. Generalized Linear Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EG5HipZf4tY4",
        "colab_type": "text"
      },
      "source": [
        "## 4.1 Introduction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtefogQm4tY5",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "The following are a set of methods intended for regression in which the target value is expected to be a linear combination of the features. In mathematical notation,\n",
        "\n",
        "$$\\hat{y}(\\theta,x)=\\theta_{0}+\\theta_{1}x_{1}+...+\\theta_{n}x_{n}$$\n",
        "- $\\hat{y}$ is the predicted value.\n",
        "- $n$ is the number of features (independent variables).\n",
        "- $x_i$ is the $i$th feature.\n",
        "- $\\theta_j$ is the $j$th model parameter (including the bias term $\\theta_0$ and the feature weights $\\theta_1,...,\\theta_n$).\n",
        "\n",
        "This equation can be written using a vectorized form $\\hat{y}=h_{\\boldsymbol{\\theta}}(\\boldsymbol{x})= \\boldsymbol{\\theta}\\boldsymbol{x}$\n",
        "\n",
        "- $\\boldsymbol{\\theta}$ is the models's parameter vector, containing the bias term $\\theta_0$ and the feature weights $\\theta_1,...,\\theta_n$.\n",
        "- $\\boldsymbol{x}$ is the instance’s feature vector, containing $x_0$ to $x_n$ , with $x_0$ always equal to 1.\n",
        "- $\\boldsymbol{\\theta}\\boldsymbol{x}$ is the dot product of the vectors $\\boldsymbol{\\theta}$ and $\\boldsymbol{x}$.\n",
        "\n",
        "**Notation** Vectors are often represented as column vectors. If $\\boldsymbol{\\theta}$ and $\\boldsymbol{x}$ are column vectors, then the prediction is: $\\hat{y}= \\boldsymbol{\\theta^T}\\boldsymbol{x}$, where $\\boldsymbol{\\theta^T}$ is the transpose of $\\boldsymbol{\\theta}$ (a row vector instead of a column vector) and $\\boldsymbol{\\theta^T}\\boldsymbol{x}$ is the matrix multiplication of $\\boldsymbol{\\theta^T}$ and $\\boldsymbol{x}$ ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKdtWGVg4tY6",
        "colab_type": "text"
      },
      "source": [
        "## 4.2 LinearRegression\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB8DqSug4tY7",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "That’s the linear regression model. Recall that training a model means setting its parameters so that the model best fits the training set. For this purpose, we first need a measure of how well the model fits the training data. The most common performance measure of a regression model is the Mean Square Error (MSE) (the residual sum of squares between the observed targets in the dataset, and the targets predicted by the linear approximation). Therefore, to train a linear regression model, you need to find the value of $\\boldsymbol{\\theta}$ that minimizes the MSE. \n",
        "\n",
        "\n",
        "$$\\text{MSE}(\\boldsymbol{\\theta})= \\frac{1}{m}\\sum_{i=1}^{m}(\\hat{y}^{(i)} - y^{(i)})=\\frac{1}{m}\\sum_{i=1}^{m}(\\boldsymbol{\\theta}^T\\boldsymbol{x}^{(i)} - y^{(i)})$$\n",
        "\n",
        "To find the value of $\\boldsymbol{\\theta}$ that minimizes the cost function (MSE), there is an explicit solution (a mathematical equation that gives the result directly). This is called the **Normal Equation** and can be calculated using the ordinary least squares method.\n",
        "\n",
        "$$\\boldsymbol{\\hat{\\theta}}=(\\boldsymbol{X^T}\\boldsymbol{X})^{-1}\\boldsymbol{X^T}\\boldsymbol{y}$$\n",
        "\n",
        "where $\\boldsymbol{\\hat{\\theta}}$ is the value of $\\boldsymbol{\\theta}$ that minimizes the cost function, $\\boldsymbol{y}$ is the vector of target values and $\\boldsymbol{X}$ is the matrix of data where the columns represent the independent variables $\\boldsymbol{X_1},...,\\boldsymbol{X_n}$ ($\\boldsymbol{X_0}$ is a 1's vector column corresponding to the bias term).\n",
        "\n",
        "The `LinearRegression` class implemented in Scikit-learn is based on the `scipy.linalg.lstsq()` function which computes $\\boldsymbol{\\hat{\\theta}}=\\boldsymbol{X^+}\\boldsymbol{y}$ where $\\boldsymbol{X^+}$ is the *pseudoinverse* of $\\boldsymbol{X}$ (specifically the Moore-Penrose inverse). The pseudoinverse is computed using a standard matrix factorization technique called *Singular Value Decomposition* (SVD). This approach is more efficient than computing the Normal Equation, plus it handles edge cases nicely: indeed, the Normal Equation may not work if the matrix $\\boldsymbol{X^T}\\boldsymbol{X}$ is not invertible (singular), such as if $m< p$  or if some features are redundant, but the pseudoinverse is always defined. The computational complexity of inverting the matrix $\\boldsymbol{X^T}\\boldsymbol{X}$ is bigger than the SVD approach used by Scikit-Learn’s `LinearRegression` class. Both the Normal Equation and the SVD approach get very slow when the number of features grows large ($100000$). On the positive side, both are linear with regards to the number of instances in the training set, so they handle large training sets efficiently."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Svs2KrIb4tY8",
        "colab_type": "text"
      },
      "source": [
        "The coefficient estimates for Ordinary Least Squares rely on the independence of the features among other assumptions like the normality of the errors. When features are correlated and the columns of the design matrix $\\boldsymbol{X}$ have an approximately linear dependence, the design matrix becomes close to singular and as a result, the least-squares estimate becomes highly sensitive to random errors in the observed target, producing a large variance. This situation of [*multicollinearity*](https://en.wikipedia.org/wiki/Multicollinearity) can arise, for example, when data are collected without an experimental design.\n",
        "\n",
        "We can train the model using fewer variables. For that, we can use different techniques to choose the most relevant variables. We can use algorithms of feature selection before to run our models or we can apply directly models which do the selection of variables innerly like regularized linear models. We could use PCA to reduce variables without loss information but we will lose certain interpretability of the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "A3TG12BL4tY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We choose the model\n",
        "model = LinearRegression()\n",
        "\n",
        "# We train the model\n",
        "fit_regression = model.fit(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgVyn0pkVqx5",
        "colab_type": "code",
        "outputId": "afacf523-c830-4c92-da10-338b01f5ced4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# We show the coefficient of determination R^2, which is the proportion of the variance in the dependent variable that is \n",
        "# predictable/explained from the independent variables.\n",
        "print('Explained variance in training set: %.3f' % fit_regression.score(x_train, y_train))\n",
        "print('Explained variance in test set: %.3f' % fit_regression.score(x_test, y_test))\n",
        "\n",
        "# We see the mean squared error\n",
        "y_pred_train = fit_regression.predict(x_train)\n",
        "y_pred_test = fit_regression.predict(x_test)\n",
        "print(\"Mean squared error in training set: %.4f\" % mean_squared_error(y_train, y_pred_train))\n",
        "print(\"Mean squared error in test set: %.4f\" % mean_squared_error(y_test, y_pred_test))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Explained variance in training set: 0.950\n",
            "Explained variance in test set: 0.899\n",
            "Mean squared error in training set: 0.0082\n",
            "Mean squared error in test set: 0.0144\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8zXmrfo4tZH",
        "colab_type": "text"
      },
      "source": [
        "Note that there are very different ways to train a linear regression model, better suited for cases where there are a large number of features or too many training instances. For example, if the training set has a large number of features we could train the linear model using an optimization algorithm like gradient descent instead using the normal equation or the SVD approach used by `LinearRegression` class implemented in Scikit-learn. Later we will use the stochastic gradient descent algorithm implemented Scikit-learn by `SGDRegressor` class to train our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2wjQ1xW4tZI",
        "colab_type": "text"
      },
      "source": [
        "## 4.3 Polynomial regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLJmdaAf4tZJ",
        "colab_type": "text"
      },
      "source": [
        "One common pattern within machine learning is to use linear models trained on nonlinear functions of the data. This approach maintains the generally fast performance of linear methods while allowing them to fit a much wider range of data.\n",
        "\n",
        "For example, a simple linear regression can be extended by constructing polynomial features from the coefficients. In the standard linear regression case, you might have a model that looks like this for two-dimensional data:\n",
        "\n",
        "$$y(\\theta_,x)=\\theta_{0}+\\theta_{1}x_{1}+\\theta_{2}x_{2}$$\n",
        "\n",
        "If we want to fit a paraboloid to the data instead of a plane, we can combine the features in second-order polynomials, so that the model looks like this:\n",
        "\n",
        "$$y(\\theta_,x)=\\theta_{0}+\\theta_{1}x_{1}+\\theta_{2}x_{2}+\\theta_{3}x_{1}x_{2}+\\theta_{4}x_{1}^{2}+\\theta_{5}x_{2}^{2}$$\n",
        "\n",
        "The (sometimes surprising) observation is that this is still a linear model: to see this, imagine creating a new set of features\n",
        "\n",
        "$$z=[x_{1},x_{2},x_{1}x_{2},x_{1}^{2},x_{2}^{2}]$$\n",
        "\n",
        "With this re-labeling of the data, our problem can be written\n",
        "\n",
        "$$y(\\theta_,x)=\\theta_{0}+\\theta_{1}z_{1}+\\theta_{2}z_{2}+\\theta_{3}z_{3}+\\theta_{4}z_{4}+\\theta_{5}z_{5}$$\n",
        "\n",
        "We see that the resulting polynomial regression is in the same class of linear models we considered above and can be solved by the same techniques. By considering linear fits within a higher-dimensional space built with these basis functions, the model has the flexibility to fit a much broader range of data.\n",
        "\n",
        "\n",
        "Here is an example of applying this idea to one-dimensional data, using polynomial features. First, let’s generate some nonlinear data, based on a simple quadratic equation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8lxuRVm4tZK",
        "colab_type": "code",
        "outputId": "1ab25468-c91f-49e2-e07d-787d8d3cc52b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "m = 100\n",
        "X = 6 * np.random.rand(m, 1) - 3\n",
        "y = 0.5 * X**2 + X + 2 + np.random.randn(m, 1)\n",
        "plt.scatter(X, y, color='b')\n",
        "plt.xlabel(\"X1\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Vy4lqezuPko",
        "colab_type": "text"
      },
      "source": [
        "A straight line will never fit this data properly. So let’s use Scikit-Learn’s `PolynomialFeatures` class to transform our training data, adding the square ($2^{\\text{nd}}$-degree polynomial) of each feature in the training set as new features (in this case there is just one feature):\n",
        "\n",
        "**Note**: `PolynomialFeatures(degree=d)` generates a new feature matrix consisting of all polynomial combinations of the features with a degree less than or equal to the specified degree $d$. Specifically, it transforms an array containing $n$ features into an array containing $\\frac{(n+d)!}{d!n!}$ \n",
        "features, where $n!$ is the [factorial](https://en.wikipedia.org/wiki/Factorial) of $n$. Beware of the combinatorial explosion of the number of features!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_wASQE04tZN",
        "colab_type": "code",
        "outputId": "735aa718-22dc-4c76-f836-19422a895587",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_poly = poly_features.fit_transform(X)\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_poly, y)\n",
        "y_predict = lin_reg.predict(X_poly)\n",
        "\n",
        "plt.scatter(X, y, color='b')\n",
        "plt.scatter(X, y_predict, color= \"r\")\n",
        "\n",
        "plt.xlabel(\"Size\")\n",
        "plt.ylabel(\"Cost\")\n",
        "plt.title(\"prediction\")\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2G0RuDp4tZS",
        "colab_type": "text"
      },
      "source": [
        "`X_poly` contains the original feature of $X$ plus the square of this feature. Then we fit a `LinearRegression` model to this extended training data.\n",
        "\n",
        "\n",
        "A high-degree Polynomial Regression model would be severely overfitting the training data, while a linear model would be underfitting it. The model that will generalize best is the quadratic model.\n",
        "\n",
        "How can you decide how complex your model should be? If a model performs well on the training data but generalizes poorly according to the cross-validation metrics, then your model is overfitting. If it performs poorly on both, then it is underfitting.\n",
        "\n",
        "Another way is to look at the learning curves: these are plots of the model’s performance on the training set and the validation set as a function of the training set size (or the training iteration). To generate the plots, simply train the model several times on different sized subsets of the training set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5efr6qG4tZT",
        "colab_type": "text"
      },
      "source": [
        "## 4.4  Regularized linear models "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nYjEPPL4tZT",
        "colab_type": "text"
      },
      "source": [
        "A good way to reduce overfitting is to regularize the model (i.e., to constrain it): the fewer degrees of freedom it has, the harder it will be for it to overfit the data. For example, a simple way to regularize a polynomial model is to reduce the number of polynomial degrees.\n",
        "\n",
        "For a linear model, regularization is typically achieved by constraining the weights of the model. We will now look at Lasso Regression, Ridge Regression, and Elastic Net, which implement three different ways to constrain the weights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9MAmdsb4tZU",
        "colab_type": "text"
      },
      "source": [
        "### 4.4.1 Lasso "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPxcJo474tZU",
        "colab_type": "text"
      },
      "source": [
        "Least Absolute Shrinkage and Selection Operator Regression (simply called *Lasso Regression*) is a linear model that estimates sparse coefficients. An important characteristic of Lasso Regression is that it tends to eliminate the weights of the least important features (i.e., set them to zero). In other words, Lasso Regression automatically performs feature selection and outputs a sparse model (i.e., with few nonzero feature weights).\n",
        "\n",
        "Mathematically, it consists of a linear model with an added regularization term to the cost function. The objective function to minimize is:\n",
        "\n",
        "\n",
        "$$J(\\boldsymbol{\\theta}) = \\text{MSE}(\\boldsymbol{\\theta})+ \\alpha \\sum_{i=1}^{n}|\\theta_i|$$\n",
        "\n",
        "\n",
        "Note that the bias term $\\theta_0$ is not regularized (the sum starts at $i = 1$, not 0). If we define $\\boldsymbol{\\omega}$ as the vector of feature weights ($\\theta_1$ to $\\theta_n$), then the regularization term is simply equal to $||\\boldsymbol{\\omega}||_{1}$, where $||\\boldsymbol{\\omega}||_{1}$ represents the $l_1$ norm of the weight vector.\n",
        "\n",
        "The lasso estimate thus solves the minimization of the least-squares penalty with $\\alpha||\\boldsymbol{\\omega}||_{1}$ added, where $\\alpha$ is a constant. The parameter $\\alpha$ controls the degree of sparsity of the estimated coefficients.\n",
        "\n",
        "The Lasso cost function is not differentiable at $\\theta_i = 0$, but Gradient\n",
        "Descent still works fine if you use a [subgradient vector](http://www.cs.cmu.edu/~ggordon/10725-F12/slides/08-general-gd.pdf) instead when any $\\theta_i = 0$.\n",
        "\n",
        "It is important to scale the data (e.g., using a `StandardScaler`) before performing Lasso Regression, as it is sensitive to the scale of the input features. This is true of most regularized models.\n",
        "\n",
        "The implementation in the class `Lasso` uses [coordinate descent](https://en.wikipedia.org/wiki/Coordinate_descent) as the algorithm to fit the coefficients. Note that you could instead use an `SGDRegressor(penalty=\"l1\")`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKNLXsnaW8sp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We scale regresor variables (target variable has already scaled)\n",
        "scaler = StandardScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)\n",
        "\n",
        "# Model\n",
        "model = Lasso(alpha=0.001)\n",
        "\n",
        "# We train the model\n",
        "fit_lasso = model.fit(x_train_scaled, y_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PYE_NUXXEqm",
        "colab_type": "code",
        "outputId": "cfdec4ca-2c01-4f07-8454-a3542d65040f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# Coefficient of determination R^2\n",
        "print('Explained variance in training set: %.3f' % fit_lasso.score(x_train_scaled, y_train))\n",
        "print('Explained variance in test set: %.3f' % fit_lasso.score(x_test_scaled, y_test))\n",
        "\n",
        "# Mean squared error\n",
        "y_pred_train = fit_lasso.predict(x_train_scaled)\n",
        "y_pred_test = fit_lasso.predict(x_test_scaled)\n",
        "\n",
        "print(\"Mean squared error in training set: %.4f\" % mean_squared_error(y_train, y_pred_train))\n",
        "print(\"Mean squared error in test set: %.4f\" % mean_squared_error(y_test, y_pred_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Explained variance in training set: 0.948\n",
            "Explained variance in test set: 0.908\n",
            "Mean squared error in training set: 0.0085\n",
            "Mean squared error in test set: 0.0131\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxFup35h4tZs",
        "colab_type": "text"
      },
      "source": [
        "All linear models find a set of coefficients to use in the weighted sum in order to make a prediction. These coefficients can be used directly as a crude type of feature importance score (this assumes that the input variables have the same scale or have been scaled prior to fitting a model). We can visualize the importance of each feature in the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJ8yYNbD4tZs",
        "colab_type": "code",
        "outputId": "6ea9e034-4446-4c35-9002-063c32d7f534",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "dict_importance_lasso = {'Features':list(x_train), 'Importance': abs(fit_lasso.coef_)}\n",
        "df_importance_lasso = pd.DataFrame(dict_importance_lasso)\n",
        "df_importance_lasso_sorted = df_importance_lasso.sort_values(by=['Importance'], ascending=False)\n",
        "df_importance_lasso_sorted.head(10)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Features</th>\n",
              "      <th>Importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>GrLivArea</td>\n",
              "      <td>0.135794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>OverallQual</td>\n",
              "      <td>0.064329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>YearBuilt</td>\n",
              "      <td>0.048287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>OverallCond</td>\n",
              "      <td>0.037732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>BsmtFinSF1</td>\n",
              "      <td>0.031994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>TotalBsmtSF</td>\n",
              "      <td>0.029879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Functional</td>\n",
              "      <td>0.029364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187</th>\n",
              "      <td>CentralAir_N</td>\n",
              "      <td>0.020738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>Neighborhood_Crawfor</td>\n",
              "      <td>0.020343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>GarageCars</td>\n",
              "      <td>0.020112</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Features  Importance\n",
              "26              GrLivArea    0.135794\n",
              "5             OverallQual    0.064329\n",
              "7               YearBuilt    0.048287\n",
              "6             OverallCond    0.037732\n",
              "17             BsmtFinSF1    0.031994\n",
              "21            TotalBsmtSF    0.029879\n",
              "35             Functional    0.029364\n",
              "187          CentralAir_N    0.020738\n",
              "82   Neighborhood_Crawfor    0.020343\n",
              "40             GarageCars    0.020112"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvsC6ZJ94tZu",
        "colab_type": "code",
        "outputId": "d20379d2-7871-4ed7-8215-19d48a3eacc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        }
      },
      "source": [
        "# plot importance of the features\n",
        "plt.figure(figsize=(15, 10))\n",
        "sns.barplot(data=df_importance_lasso_sorted.head(20), x='Importance', y = 'Features')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1c5f3eee10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUbj4eBSmpOG",
        "colab_type": "text"
      },
      "source": [
        "We show all the coefficients or weights of the model. Notice that only a few weights are nonzero."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3rPv5tdmqhD",
        "colab_type": "code",
        "outputId": "be40fa83-bf11-4356-f394-bc0d68a32729",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(fit_lasso.coef_)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.00000000e+00 -8.50213207e-03  1.87327500e-02  1.77173697e-02\n",
            " -4.01687390e-03  6.43294951e-02  3.77321720e-02  4.82868803e-02\n",
            "  1.43777358e-02  9.32435154e-03 -3.12351669e-04  5.15084511e-04\n",
            " -2.69721484e-03  7.19110792e-03 -1.05408884e-03  1.55588403e-02\n",
            "  3.34935039e-03  3.19941551e-02 -0.00000000e+00  2.31703917e-03\n",
            " -0.00000000e+00  2.98785284e-02  8.26314933e-03  7.34046183e-03\n",
            "  0.00000000e+00  0.00000000e+00  1.35794147e-01  1.21243887e-02\n",
            "  2.89770682e-03  1.47491344e-02  8.93816085e-03  0.00000000e+00\n",
            " -9.52197221e-03  1.42839320e-02  1.45641517e-03  2.93635593e-02\n",
            "  3.31090732e-04  1.14786956e-02  0.00000000e+00  0.00000000e+00\n",
            "  2.01120125e-02  9.13582469e-03  7.68328558e-03  0.00000000e+00\n",
            "  7.91863449e-03  9.97300964e-03  6.57857888e-03  1.57553881e-03\n",
            "  1.65576403e-02  4.08424278e-06  5.45491149e-03  0.00000000e+00\n",
            " -2.41555791e-03 -0.00000000e+00 -1.70912003e-02  0.00000000e+00\n",
            "  1.85307393e-03  0.00000000e+00 -1.24496394e-02 -1.31671399e-04\n",
            "  3.64380890e-18 -1.29667867e-03 -0.00000000e+00  4.61844920e-03\n",
            " -1.34709788e-03  1.53611011e-03 -1.80389392e-03  0.00000000e+00\n",
            "  2.71732918e-03  8.62293757e-03 -2.74892233e-03 -2.71845060e-03\n",
            " -0.00000000e+00 -0.00000000e+00  1.98622947e-03 -5.87765022e-03\n",
            " -0.00000000e+00  1.22114520e-03 -2.56826087e-03  2.27622475e-03\n",
            "  7.40431575e-03 -5.77410465e-05  2.03432010e-02 -5.23361174e-03\n",
            " -8.19487888e-04  0.00000000e+00 -1.25010431e-02 -3.00298510e-03\n",
            " -0.00000000e+00  0.00000000e+00 -3.32431484e-03  1.63335136e-03\n",
            "  1.75417199e-02 -3.60622214e-03  3.71482301e-03  2.67878581e-03\n",
            " -3.07477937e-04  9.79869763e-03  1.81679915e-02  0.00000000e+00\n",
            "  5.77508031e-03 -8.10095858e-03 -0.00000000e+00  1.22995922e-02\n",
            " -6.66830733e-03 -5.33620124e-04 -2.26561026e-03  9.50630942e-04\n",
            " -6.41348665e-05  1.15620317e-03 -5.80052426e-04  6.25537847e-04\n",
            " -0.00000000e+00  3.41920335e-03 -1.86256046e-03 -5.67732813e-03\n",
            "  0.00000000e+00  0.00000000e+00  6.54934481e-03  4.33302749e-03\n",
            " -0.00000000e+00 -5.59143293e-03 -0.00000000e+00 -2.80918891e-04\n",
            "  3.12919366e-03  0.00000000e+00 -8.87308482e-03  1.37306392e-03\n",
            " -0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            " -7.90272816e-04  1.31379165e-03  0.00000000e+00  1.89708077e-03\n",
            "  4.11208604e-03 -0.00000000e+00  0.00000000e+00  4.19015831e-03\n",
            "  0.00000000e+00 -6.93096391e-03  2.22031314e-03  6.64327465e-03\n",
            " -0.00000000e+00  0.00000000e+00 -6.54733473e-03  1.87071265e-02\n",
            " -1.09281920e-03 -0.00000000e+00 -1.10067734e-02  0.00000000e+00\n",
            "  0.00000000e+00 -2.84012485e-03  0.00000000e+00  4.04088058e-03\n",
            "  0.00000000e+00 -5.84833147e-03  1.50071223e-04 -7.46103688e-03\n",
            "  0.00000000e+00  1.58937068e-03 -7.73944648e-03 -1.96844454e-04\n",
            "  1.30068142e-03 -0.00000000e+00  4.37410586e-04  0.00000000e+00\n",
            " -2.67694372e-03 -0.00000000e+00 -6.24083770e-04 -1.03262914e-03\n",
            " -0.00000000e+00  2.74864127e-03 -1.29077841e-03 -0.00000000e+00\n",
            " -0.00000000e+00  1.18384626e-02 -0.00000000e+00 -0.00000000e+00\n",
            " -6.45390810e-03 -1.09448188e-03 -0.00000000e+00  7.68308416e-03\n",
            " -1.19122824e-03 -4.93460790e-04  5.37667410e-03 -2.07375899e-02\n",
            "  6.45181914e-16 -0.00000000e+00 -1.50845721e-03 -0.00000000e+00\n",
            "  0.00000000e+00  4.77409823e-04 -2.29030146e-03 -0.00000000e+00\n",
            " -1.26788154e-03  0.00000000e+00 -3.86305008e-03  0.00000000e+00\n",
            "  0.00000000e+00 -0.00000000e+00 -4.94474989e-03  3.04498869e-04\n",
            "  0.00000000e+00 -2.18212691e-03 -0.00000000e+00 -1.19073098e-04\n",
            "  1.25863150e-03  0.00000000e+00  0.00000000e+00 -8.02504984e-04\n",
            " -0.00000000e+00 -7.73845529e-03 -7.80530279e-04  8.73756456e-04\n",
            "  3.86643736e-03  2.48741726e-03 -2.64053494e-03  0.00000000e+00\n",
            "  1.08728835e-02  2.48867881e-03 -2.64515045e-03 -1.49348579e-02\n",
            " -0.00000000e+00 -3.95085810e-03 -9.57742179e-03  0.00000000e+00\n",
            "  0.00000000e+00]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c89PYHSv4tZw",
        "colab_type": "text"
      },
      "source": [
        "`LassoCV` is used to estimate the parameter using cross-validation.\n",
        "For high-dimensional datasets with many collinear features, `LassoCV` is most often preferable.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": false,
        "_kg_hide-output": true,
        "scrolled": true,
        "id": "kHDnZImR4tZz",
        "colab_type": "code",
        "outputId": "9b1ee959-249b-4a20-bc7d-d284497ee73c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model_lassoCV = LassoCV( alphas=np.arange(0.001,0.5,0.001), cv=5, random_state=0, max_iter=10000)\n",
        "\n",
        "# We train the model\n",
        "fit_lassoCV = model_lassoCV.fit(x_train_scaled, y_train)\n",
        "\n",
        "print(fit_lassoCV.alpha_)\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa-6bjw64tZ-",
        "colab_type": "text"
      },
      "source": [
        "### 4.4.2 Ridge "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dE3-N1kp4tZ-",
        "colab_type": "text"
      },
      "source": [
        "*Ridge regression* addresses some of the problems of ordinary least squares by imposing a penalty on the size of the coefficients. A regularization term is added to the cost function. This forces the learning algorithm to not only fit the data but also keep the model weights as small as possible.\n",
        "\n",
        "The ridge coefficients minimize a penalized residual sum of squares:\n",
        "\n",
        "\n",
        "$$ J(\\boldsymbol{\\theta})= \\text{MSE}(\\boldsymbol{\\theta})+ \\alpha \\frac{1}{2} \\sum_{i=1}^{n}\\theta_i^2$$\n",
        "\n",
        "Note that the bias term $\\theta_0$ is not regularized (the sum starts at $i = 1$, not 0). If we define $\\boldsymbol{\\omega}$ as the vector of feature weights ($\\theta_1$ to $\\theta_n$), then the regularization term is simply equal to $\\frac{1}{2}||\\boldsymbol{\\omega}||_{2}^{2}$, where $||\\boldsymbol{\\omega}||_{2}$ represents the $l_2$ norm of the weight vector.\n",
        "\n",
        "\n",
        "The complexity hyperparameter $\\alpha < 0$ controls how much you want to regularize the model: the larger the value of $\\alpha$, the greater the amount of shrinkage and thus the coefficients become more robust to collinearity. If $\\alpha=0$ then Ridge Regression is just Linear Regression.\n",
        "\n",
        "\n",
        "\n",
        "**Note**: As with Linear Regression, we can perform Ridge Regression either by computing a closed-form equation or by performing Gradient Descent (using `SGDRegressor` and selecting `penalty=\"l2\"`). The pros and cons are the same. The next equation shows the closed-form solution (where $\\boldsymbol{A}$ is the $(n + 1) × (n + 1)$ [identity matrix](https://en.wikipedia.org/wiki/Identity_matrix#:~:text=In%20linear%20algebra%2C%20the%20identity,trivially%20determined%20by%20the%20context.) except with a 0 in the top-left cell, corresponding to the bias term).\n",
        "\n",
        "$$\\boldsymbol{\\hat{\\theta}}=(\\boldsymbol{X^T}\\boldsymbol{X}+\\alpha\\boldsymbol{A})^{-1}\\boldsymbol{X^T}\\boldsymbol{y}$$\n",
        "\n",
        "Here is how to perform Ridge Regression with Scikit-Learn using a closed-form solution (a variant of the previous equation using a matrix factorization technique by André-Louis Cholesky)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSzvcYd6dG6c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We choose the model\n",
        "model = Ridge(alpha=1, solver=\"cholesky\")\n",
        "\n",
        "# We train the model\n",
        "fit_ridge = model.fit(x_train_scaled, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRoJ8NOLYJXf",
        "colab_type": "code",
        "outputId": "85a93bff-64bd-468e-d7ad-a0b413d46188",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# Coefficient of determination R^2\n",
        "print('Explained variance in training set: %.3f' % fit_ridge.score(x_train_scaled, y_train))\n",
        "print('Explained variance in test set: %.3f' % fit_ridge.score(x_test_scaled, y_test))\n",
        "\n",
        "# Mean squared error\n",
        "y_pred_train = fit_ridge.predict(x_train_scaled)\n",
        "y_pred_test = fit_ridge.predict(x_test_scaled)\n",
        "\n",
        "print(\"Mean squared error in training set: %.4f\" % mean_squared_error(y_train, y_pred_train))\n",
        "print(\"Mean squared error in test set: %.4f\" % mean_squared_error(y_test, y_pred_test))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Explained variance in training set: 0.950\n",
            "Explained variance in test set: 0.899\n",
            "Mean squared error in training set: 0.0082\n",
            "Mean squared error in test set: 0.0144\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IH8Qrm0O4taN",
        "colab_type": "text"
      },
      "source": [
        "We can use `RidgeCV` that implements ridge regression with built-in cross-validation of the `alpha` parameter similarly to `LassoCV`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBL1FNHR4taN",
        "colab_type": "text"
      },
      "source": [
        "### 4.4.3 ElasticNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLWOgVDL4taO",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "ElasticNet is a linear regression model trained with both $l_{1}$ and $l_{2}$-norm regularization of the coefficients. This combination allows for learning a sparse model where few of the weights are non-zero like Lasso, while still maintaining the regularization properties of Ridge. We control the convex combination of $l_{1}$ and $l_{2}$ using the $r$ parameter. When $r=0$, Elastic Net is equivalent to Ridge Regression, and when $r=1$, it is equivalent to Lasso Regression\n",
        "\n",
        "Elastic-net is useful when multiple features are correlated with one another. Lasso is likely to pick one of these at random, while elasticnet is likely to pick both.\n",
        "\n",
        "The objective function to minimize in this case is:\n",
        "\n",
        "\n",
        "$$J(\\boldsymbol{\\theta})=\\text{MSE}(\\boldsymbol{\\theta}) + \\alpha r\\sum_{i=1}^{n}|\\theta_i|+\\frac{\\alpha(1-r)}{2}\\sum_{i=1}^{n}\\theta_i^2$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUvkfF_MYeMj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We choose the model\n",
        "model = ElasticNet(alpha=0.0098, l1_ratio=0.4)\n",
        "\n",
        "# We train the model\n",
        "fit_elasticnet = model.fit(x_train_scaled, y_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GeIeMPh4taW",
        "colab_type": "code",
        "outputId": "99afebea-0088-4601-e7da-775ea3e6c3cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# Coefficient of determination R^2\n",
        "print('Explained variance in training set: %.3f' % fit_elasticnet.score(x_train_scaled, y_train))\n",
        "print('Explained variance in test set: %.3f' % fit_elasticnet.score(x_test_scaled, y_test))\n",
        "\n",
        "# Mean squared error\n",
        "y_pred_train = fit_elasticnet.predict(x_train_scaled)\n",
        "y_pred_test = fit_elasticnet.predict(x_test_scaled)\n",
        "print(\"Mean squared error train: %.4f\" % mean_squared_error(y_train, y_pred_train))\n",
        "print(\"Mean squared error test: %.4f\" % mean_squared_error(y_test, y_pred_test))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Explained variance in training set: 0.940\n",
            "Explained variance in test set: 0.910\n",
            "Mean squared error train: 0.0099\n",
            "Mean squared error test: 0.0128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMERDDZO4taa",
        "colab_type": "text"
      },
      "source": [
        "We can visualize the importance of each feature in the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyEo_tbW4taa",
        "colab_type": "code",
        "outputId": "0eb9a1de-1b23-4b4b-82e6-502c2ac4d2a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "dict_importance_elasticnet = {'Features':list(x_train), 'Importance': abs(fit_elasticnet.coef_)}\n",
        "df_importance_elasticnet = pd.DataFrame(dict_importance_elasticnet)\n",
        "df_importance_elasticnet_sorted = df_importance_elasticnet.sort_values(by=['Importance'], ascending=False)\n",
        "df_importance_elasticnet_sorted.head(10)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Features</th>\n",
              "      <th>Importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>GrLivArea</td>\n",
              "      <td>0.132679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>OverallQual</td>\n",
              "      <td>0.076425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>YearBuilt</td>\n",
              "      <td>0.039394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>TotalBsmtSF</td>\n",
              "      <td>0.036071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>OverallCond</td>\n",
              "      <td>0.032791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>BsmtFinSF1</td>\n",
              "      <td>0.031376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Functional</td>\n",
              "      <td>0.025974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>GarageCars</td>\n",
              "      <td>0.024596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>MSZoning_RM</td>\n",
              "      <td>0.018801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>KitchenQual</td>\n",
              "      <td>0.016383</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Features  Importance\n",
              "26    GrLivArea    0.132679\n",
              "5   OverallQual    0.076425\n",
              "7     YearBuilt    0.039394\n",
              "21  TotalBsmtSF    0.036071\n",
              "6   OverallCond    0.032791\n",
              "17   BsmtFinSF1    0.031376\n",
              "35   Functional    0.025974\n",
              "40   GarageCars    0.024596\n",
              "58  MSZoning_RM    0.018801\n",
              "33  KitchenQual    0.016383"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjhgBC134tah",
        "colab_type": "code",
        "outputId": "b853b509-0c1d-4539-d2a0-b9d3c6d5c6a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        }
      },
      "source": [
        "# plot importance of the features\n",
        "plt.figure(figsize=(15, 10))\n",
        "sns.barplot(data=df_importance_elasticnet_sorted.head(20), x='Importance', y = 'Features')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1c5f405ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0ZSVYH24tam",
        "colab_type": "text"
      },
      "source": [
        "The class `ElasticNetCV` can be used to set the parameters `alpha` ($\\alpha$) and `l1_ratio` ($r$) by cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "PM6bWITW4tan",
        "colab_type": "code",
        "outputId": "4878f752-2be4-4632-c5df-4c97e12a78e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "model_elasticNetCV = ElasticNetCV(alphas=np.arange(0.0001,0.01,0.0001),\n",
        "                                  l1_ratio=np.arange(0.1,1,0.1), cv=5)\n",
        "\n",
        "# We train the model\n",
        "fit_elasticNetCV = model_elasticNetCV.fit(x_train_scaled, y_train)\n",
        "\n",
        "print(fit_elasticNetCV.alpha_)\n",
        "print(fit_elasticNetCV.l1_ratio_)\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0098\n",
            "0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IxPtosk4tav",
        "colab_type": "text"
      },
      "source": [
        "So when should you use plain Linear Regression (i.e., without any regularization), Ridge, Lasso, or Elastic Net? It is almost always preferable to have at least a little bit of regularization, so generally you should avoid plain Linear Regression. Ridge is a good default, but if you suspect that only a few features are useful, you should prefer Lasso or Elastic Net since they tend to reduce the useless features weights down to zero as we have discussed. In general, Elastic Net is preferred over Lasso since Lasso may behave erratically when the number of features is greater than the number of training instances or when several features are strongly correlated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jw2a0x804aJk",
        "colab_type": "text"
      },
      "source": [
        "## 4.5 Robustness regression\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUS1LNkb4fBU",
        "colab_type": "text"
      },
      "source": [
        "### Huber Regression\n",
        "\n",
        "The *HuberRegressor* applies a linear loss to samples that are classified as [outliers](https://en.wikipedia.org/wiki/Outlier). A sample is classified as an outlier if the absolute error of that sample is lesser than a certain threshold. It does not ignore the effect of the outliers but gives a lesser weight to them.\n",
        "\n",
        "The loss function that HuberRegressor minimizes is given by\n",
        "\n",
        "$$J(\\boldsymbol{\\theta})= \\sum_{i=1}^{m}(\\sigma+H_{\\epsilon}(\\frac{\\boldsymbol{\\theta}^T\\boldsymbol{x}^{(i)} - y^{(i)}}{\\sigma})\\sigma)+\\alpha||\\boldsymbol{\\theta}||_{2}^{2}$$\n",
        "\n",
        "where\n",
        "\n",
        "$$H_{\\epsilon}(z)=\\begin{cases}\n",
        "       z^{2} ,&\\quad\\text{if}|z|\\le\\epsilon\\\\\n",
        "       2\\epsilon|z|-\\epsilon^{2} ,&\\quad\\text{otherwhise}\\\\\n",
        "     \\end{cases}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0gO0iOS4iQC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = HuberRegressor(alpha=0.006,epsilon=3.6,max_iter=1000)\n",
        "\n",
        "# We train the model\n",
        "fit_huber = model.fit(x_train_scaled, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DvvLIdw4itS",
        "colab_type": "code",
        "outputId": "973691aa-3947-49ab-902d-548a48849dd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# Coefficient of determination R^2\n",
        "print('Explained variance in training: %.3f' % fit_huber.score(x_train_scaled, y_train))\n",
        "print('Explained variance in test set: %.3f' % fit_huber.score(x_test_scaled, y_test))\n",
        "\n",
        "# Mean squared error\n",
        "y_pred_train = fit_huber.predict(x_train_scaled)\n",
        "y_pred_test = fit_huber.predict(x_test_scaled)\n",
        "print(\"Mean squared error in training set: %.4f\" % mean_squared_error(y_train, y_pred_train))\n",
        "print(\"Mean squared error in test set: %.4f\" % mean_squared_error(y_test, y_pred_test))\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Explained variance in training: 0.950\n",
            "Explained variance in test set: 0.899\n",
            "Mean squared error in training set: 0.0082\n",
            "Mean squared error in test set: 0.0143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXpwxdhj4qbk",
        "colab_type": "text"
      },
      "source": [
        "We can tune some hyperparameters of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nusv5GhX4q0m",
        "colab_type": "code",
        "outputId": "a90fff36-637c-4787-9936-9986cb2d5e69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "\n",
        "# We choose the model\n",
        "model_huber = HuberRegressor()\n",
        "\n",
        "# We input possible values of parameters\n",
        "param_grid = {\n",
        "    'epsilon': np.arange(1,5,0.1),\n",
        "    'alpha': np.arange(0.001,0.01,0.005),\n",
        "}\n",
        "clf = GridSearchCV(model_huber, param_grid, cv=5, n_jobs=5)\n",
        "\n",
        "# We train the model for diferent values of parameters\n",
        "clf.fit(x_train_scaled, y_train)\n",
        "\n",
        "clf.best_params_"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_huber.py:296: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alpha': 0.006, 'epsilon': 3.6000000000000023}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoINTQA34taw",
        "colab_type": "text"
      },
      "source": [
        "## 4.6 Stochastic Gradient Descent - SGD\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qm3gtPYr4tax",
        "colab_type": "text"
      },
      "source": [
        "SGD stands for Stochastic Gradient Descent: the gradient of the loss is estimated each sample at a time and the model is updated along the way with a decreasing strength schedule (aka learning rate). More info about gradient descent algorithm [here](https://github.com/victorviro/ML_algorithms_python/blob/master/Introduction_gradient_descent_algorithm.ipynb).\n",
        "\n",
        "The regularizer is a penalty added to the loss function that shrinks model parameters towards the zero vector using either the squared euclidean norm $l_2$ or the absolute norm $l_1$ or a combination of both (Elastic Net).\n",
        "\n",
        "Stochastic gradient descent is a simple yet very efficient approach to fit linear models. It is particularly useful when the number of samples (and the number of features) is very large.\n",
        "\n",
        "The classes `SGDRegressor` provides functionality to fit linear models for regression using different (convex) loss functions and different penalties.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "AzIvrgNH4ta3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5d0ffa4e-1dfd-4d8d-e87e-4f7689ff7a50"
      },
      "source": [
        "model_SGD = SGDRegressor()\n",
        "\n",
        "# We input possible values of parameters\n",
        "param_grid = {\n",
        "    'alpha': np.arange(0.01,0.1,0.01),\n",
        "    'loss': ['squared_loss', 'huber'],\n",
        "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
        "    'learning_rate': ['constant', 'optimal', 'invscaling'],\n",
        "}\n",
        "\n",
        "grid_SGD = GridSearchCV(model_SGD, param_grid, cv=5, n_jobs=5)\n",
        "\n",
        "# We train the model\n",
        "fit_SGD = grid_SGD.fit(x_train_scaled, y_train)\n",
        "print(fit_SGD.best_params_)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'alpha': 0.02, 'learning_rate': 'optimal', 'loss': 'huber', 'penalty': 'elasticnet'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZICma9cvD45g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "61b1018c-5dd0-4b00-fb99-6ea27552f58b"
      },
      "source": [
        "# Coefficient of determination R^2\n",
        "print('Explained variance in training set: %.3f' % fit_SGD.score(x_train_scaled, y_train))\n",
        "print('Explained variance in test set: %.3f' % fit_SGD.score(x_test_scaled, y_test))\n",
        "\n",
        "# Mean squared error\n",
        "y_pred_train = fit_SGD.predict(x_train_scaled)\n",
        "y_pred_test = fit_SGD.predict(x_test_scaled)\n",
        "print(\"Mean squared error in training set: %.4f\" % mean_squared_error(y_train, y_pred_train))\n",
        "print(\"Mean squared error in test set: %.4f\" % mean_squared_error(y_test, y_pred_test))\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Explained variance in training set: 0.922\n",
            "Explained variance in test set: 0.888\n",
            "Mean squared error in training set: 0.0127\n",
            "Mean squared error in test set: 0.0160\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v83HQbY64ta9",
        "colab_type": "text"
      },
      "source": [
        "A very different way to regularize iterative learning algorithms such as Gradient Descent is to stop training as soon as the validation error reaches a minimum. This is called *early stopping*. We can implement this setting the parameter `warm_start=True` when we define the `SGDRegressor` model.\n",
        "\n",
        "**Note** With Stochastic and Mini-batch Gradient Descent, the curves are not so smooth, and it may be hard to know whether you have reached the minimum or not. One solution is to stop only after the validation error has been above the minimum for some time (when you are confident that the model will not do any better)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DP_sr3OurhZO",
        "colab_type": "text"
      },
      "source": [
        "## 4.7 Logistic regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGXpoZk7AeDj",
        "colab_type": "text"
      },
      "source": [
        "We have seen how we can make predictions using linear regression. In this section, we will dive deep into the generalized model of linear regression for classification instead of prediction. *Logistic regression* (also called *logit regression*) is a linear classifier. It calculates the probability of two classes between 0 and 1. We can simply classify an item if it’s probability score is less than 0.5 is classified in class 0 (negative class) otherwise in class 1 (positive class)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4Zt8TL3AevP",
        "colab_type": "text"
      },
      "source": [
        "#### 4.7.1 Estimating probabilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqw5JYcvrkQc",
        "colab_type": "text"
      },
      "source": [
        "Just like a Linear Regression model, a Logistic Regression model computes a weighted sum of the input features (plus a bias term), but instead of outputting the result directly like the Linear Regression model does, it outputs the logistic of this result.\n",
        "\n",
        "$$\\hat{p}=h_{\\boldsymbol{\\theta}}(\\boldsymbol{x})=\\sigma(\\boldsymbol{\\theta^T}\\boldsymbol{x})=\\frac{1}{1+e^{-\\boldsymbol{\\theta^T}\\boldsymbol{x}}}$$\n",
        "\n",
        "- $\\sigma(.)$ is the logistic function (also called *sigmoid*) that outputs a number between 0 and 1.\n",
        "- $\\hat{p}$ is the probability estimated that the target variable $Y$ is equal to 1 given the input features $\\boldsymbol{x}$, this is, the estimation of $P(Y=1|X=\\boldsymbol{x})$\n",
        "\n",
        "The linear regression model is not good for binary classification because we want $\\hat{p} \\in (0,1)$ and $\\boldsymbol{\\theta^T}\\boldsymbol{x}$ can be much bigger or can even be negative which does not sense for probability. Applying the sigmoid function we get values between 0 and 1.\n",
        "\n",
        "\n",
        "![texto alternativo](https://i.ibb.co/QX4tRCc/logistic-function.png)\n",
        "\n",
        "Notice that if $t$ is large, then $\\sigma(t) \\approx \\frac{1}{1+0}=1$, and conversely, if $t$ is small, then $\\sigma(t) \\approx \\frac{1}{1+\\infty}=0$ (see figure 4-21).\n",
        "\n",
        "\n",
        "\n",
        "Once the Logistic Regression model has estimated the probability $\\hat{p}$ that an instance $\\boldsymbol{x}$ belongs to the positive class, it can make its prediction $\\hat{y}$ easily.\n",
        "\n",
        "$$\n",
        "   \\hat{y}  = \\begin{cases}\n",
        "               0 & \\text{if } \\hat{p} < 0.5\\\\\n",
        "               1 & \\text{if } \\hat{p} \\geq 0.5\n",
        "          \\end{cases}\n",
        "$$\n",
        "\n",
        "**Note**: The *Odds* are defined as the probability that the event will occur divided by the probability that the event will not occur. If the probability of success is $P$, then the odds of that event is: $\\text{odds} = \\frac{P}{1-P}$. We can use a linear regression model to predict the log of the odds (*logit* function), this is, $\\text{logit}(P)=ln(\\frac{P}{1-P}) = \\boldsymbol{\\theta^T}\\boldsymbol{x} \\implies \\frac{P}{1-P} = e^{\\boldsymbol{\\theta^T}\\boldsymbol{x}} \\implies P = \\frac{e^{\\boldsymbol{\\theta^T}\\boldsymbol{x}}}{1+e^{\\boldsymbol{\\theta^T}\\boldsymbol{x}}}=\\frac{1}{1+e^{-\\boldsymbol{\\theta^T}\\boldsymbol{x}}} = \\sigma(\\boldsymbol{\\theta^T}\\boldsymbol{x})$\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEQ-zVycF_wf",
        "colab_type": "text"
      },
      "source": [
        "#### 4.7.2 Training and cost function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8xPR_o0GEGT",
        "colab_type": "text"
      },
      "source": [
        "The objective of the training process is to set the parameter vector $\\boldsymbol{\\theta}$ so that the model estimates high probabilities for positive instances ($y =\n",
        "1$) and low probabilities for negative instances ($y = 0$).\n",
        "\n",
        "Linear regression uses the MSE as loss function that gives a convex graph and then we can complete the optimization by finding its global minimum. However, it’s not an option for logistic regression since the hypothesis is changed, the MSE will result in a non-convex graph with local minimums so gradient descent may not find a global optimum.\n",
        "\n",
        "![texto alternativo](https://i.ibb.co/qJq6h4L/local-minima.png)\n",
        "\n",
        "Instead of MSE, we use a cost function for a single training instance $\\boldsymbol{x}$ (logistic loss):\n",
        "\n",
        "$$\n",
        "   c(h_{\\boldsymbol{\\theta}}(\\boldsymbol{x}),y)  = \\begin{cases}\n",
        "               -log(\\hat{p}) & \\text{if } y = 1\\\\\n",
        "               -log(1-\\hat{p}) & \\text{if } y=0\n",
        "          \\end{cases}\n",
        "$$\n",
        "\n",
        "This cost function makes sense because $-log(t)$ grows very large when $t$ approaches 0, so the cost will be large if the model estimates a probability close to 0 for a positive instance, and it will also be very large if the model estimates a probability close to 1 for a negative instance. On the other hand, $-log(t)$ is close to 0 when t is close to 1, so the cost will be close to 0 if the estimated probability is close to 0 for a negative\n",
        "instance or close to 1 for a positive instance, which is precisely what we want.\n",
        "\n",
        "Another advantage of this loss function is that although we are looking at it by $y = 1$ and $y = 0$ separately, it can be written as one single formula which brings convenience for calculation:\n",
        "\n",
        "$$c(h_{\\boldsymbol{\\theta}}(\\boldsymbol{x}),y)=-ylog(\\hat{p})+(1-y)log(1-\\hat{p})$$\n",
        "\n",
        "The cost function over the whole training set is simply the average cost over all training instances. It can be written in a single expression called\n",
        "the *log loss*:\n",
        "\n",
        "$$J(\\boldsymbol{\\theta})=\\frac{1}{m}\\sum_{i=1}^{m}c(h_{\\boldsymbol{\\theta}}(\\boldsymbol{x}^{(i)}),y^{(i)})= -\\frac{1}{m}\\sum_{i=1}^{m}y^{(i)}log(\\hat{p}^{(i)})+(1-y^{(i)})log(1-\\hat{p}^{(i)})$$\n",
        "\n",
        "There is no analytical solution to compute the value of $\\boldsymbol{\\theta}$ that minimizes this cost function (there is no equivalent of the Normal Equation). But this cost function is convex, so Gradient Descent (or any other optimization algorithm such as [Newton–Raphson method](https://en.wikipedia.org/wiki/Newton%27s_method)) is guaranteed to find the global minimum (if the learning rate is not too large and you wait long enough if we use Gradient Descent). The partial derivatives of the cost function with regards to the parameter $\\theta_j$, $\\frac{\\partial J(\\boldsymbol{\\theta})}{\\partial\\theta_j}$, can be easily calculated. Once you have the gradient vector containing all the partial derivatives you can use it in the Batch Gradient Descent algorithm.\n",
        "\n",
        "\n",
        "\n",
        "**Note**: In statistics, *maximum likelihood estimation* ([MLE](https://en.wikipediaorgwikiMaximum_likelihood_estimation#:~:text=In%20statistics%2C%20maximum%20likelihood%20estimation,observed%20data%20is%20most%20probable.)) is widely used to obtain the parameter for a distribution. To use maximum likelihood, we need to assume a probability distribution. In the case of logistic regression, a Binomial probability distribution is assumed for the data sample, where each example is one outcome of a Bernoulli trial. In this context, calculating the negative of the log-likelihood function for the Bernoulli distribution is equivalent to calculating the log loss function for the Bernoulli distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNxvnDarRtM2",
        "colab_type": "text"
      },
      "source": [
        "#### 4.7.3 Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dakgg1vbHE-4",
        "colab_type": "text"
      },
      "source": [
        "Let’s use the [iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set) to illustrate Logistic Regression. This is a famous dataset that contains the sepal and petal length and width of 150 iris flowers of three different species: Iris-Setosa, Iris-Versicolor, and Iris-Virginica.\n",
        "\n",
        "Let’s try to build a classifier to detect the Iris-Virginica type based only on the petal width feature. First, let’s load the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SBNMybtxl6O",
        "colab_type": "code",
        "outputId": "cb245853-2b79-451b-bad3-0c2f568c4159",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn import datasets\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "print(list(iris.keys()))\n",
        "X = iris[\"data\"][:, 3:] # petal width\n",
        "y = (iris[\"target\"] == 2).astype(np.int)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qbcFNViHth2",
        "colab_type": "text"
      },
      "source": [
        "Now let’s train a Logistic Regression model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8rnGdwYHuHl",
        "colab_type": "code",
        "outputId": "e8b22f9b-be26-4012-9c63-ebc1edf010bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(X, y)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWd9U9HRHycq",
        "colab_type": "text"
      },
      "source": [
        "Let’s look at the model’s estimated probabilities for flowers with petal widths varying from 0 to 3 cm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoEJG4fVH0I9",
        "colab_type": "code",
        "outputId": "d5963cbf-e68b-4eb8-ce68-5601a35be068",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "X_new = np.linspace(0, 3, 1000).reshape(-1, 1)\n",
        "y_proba = log_reg.predict_proba(X_new)\n",
        "\n",
        "plt.scatter(X, y, c='black', s=2)\n",
        "plt.plot(X_new, y_proba[:, 1], \"g-\", label=\"Iris-Virginica\")\n",
        "plt.plot(X_new, y_proba[:, 0], \"b--\", label=\"Not Iris-Virginica\")\n",
        "\n",
        "plt.xlabel(\"Petal Width (cm)\")\n",
        "plt.ylabel(\"Probability is Virginica\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtiCb9gILMxE",
        "colab_type": "text"
      },
      "source": [
        "The petal width of Iris-Virginica flowers ranges from 1.4 cm to 2.5 cm, while the other iris flowers (not Iris-Virginica) generally have a smaller petal width, ranging from 0.1 cm to 1.8 cm. Notice that there is a bit of overlap. Above about 2 cm the classifier is highly confident that the flower is an Iris-Virginica (it outputs a high probability to that class), while below 1 cm it is highly confident that it is not an Iris-Virginica (high probability for the “Not Iris-Virginica” class). In between these extremes, the classifier is unsure. However, if you ask it to predict the class (using the `predict()` method rather than the `predict_proba()` method), it will return whichever class is the most likely. Therefore, there is a decision boundary at around 1.6 cm where both probabilities are equal to 50%: if the petal width is higher than 1.6 cm, the classifier will predict that the flower is an Iris-Virginica, or else it will predict that it is not (even if it is not very confident):\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XazFhfoAL03t",
        "colab_type": "code",
        "outputId": "3d3ae706-5cd6-4a88-ceb5-000f45a3948a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "log_reg.predict([[1.7], [1.5]])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSpWFYh1MP8F",
        "colab_type": "text"
      },
      "source": [
        "Figure 4-24 shows the same dataset but this time displaying two features: petal width and length. Once trained, the Logistic Regression classifier can estimate the probability that a new flower is an Iris-Virginica based on these two features. \n",
        "\n",
        "![alt text](https://i.ibb.co/r06mngv/decision-boundary-logistic-regression-png.png)\n",
        "\n",
        "\n",
        "The dashed line represents the points where the model estimates a 50% probability: this is the model’s decision boundary. Note that it is a linear boundary. Each parallel line represents the points where the model outputs a specific probability, from 15% (bottom left) to 90% (top right). All the flowers beyond the top-right line have an over 90% chance of being Iris-Virginica according to the model.\n",
        "\n",
        "Just like the other linear models, Logistic Regression models can be regularized using $l_1$ or $l_2$ penalties. Scitkit-Learn actually adds an $l_2$ penalty by default. The hyperparameter controlling the regularization strength of a Scikit-Learn `LogisticRegression` model is not alpha (as in other\n",
        "linear models), but its inverse: `C` . The higher the value of `C`, the less\n",
        "the model is regularized.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcH8MEwvM2i9",
        "colab_type": "text"
      },
      "source": [
        "#### 4.7.4 Multinomial logistic regression\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fej4U55SM9I4",
        "colab_type": "text"
      },
      "source": [
        "The Logistic Regression model can be generalized to support multiple classes directly. This is called *Softmax Regression*, or *Multinomial Logistic Regression*.\n",
        "\n",
        "The idea is quite simple: when given an instance $\\boldsymbol{x}$, the Softmax Regression model first computes a score $s_{k}(\\boldsymbol{x})$ for each class $k$, then estimates the probability of each class by applying the *softmax function* (also called the *normalized exponential*) to the scores. The equation to compute $s_{k}(\\boldsymbol{x})$ is just like the equation for Linear Regression prediction.\n",
        "\n",
        "$$s_{k}(\\boldsymbol{x})=\\boldsymbol{x}^T\\boldsymbol{\\theta}^{(k)}$$\n",
        "\n",
        "Each class has its own dedicated parameter vector $\\boldsymbol{\\theta}^{(k)}$ . All these vectors are usually stored as rows in a parameter matrix $\\boldsymbol{\\Theta}$.\n",
        "\n",
        "Once you have computed the score of every class for the instance $\\boldsymbol{x}$, you can estimate the probability $\\hat{p}_k$ that the instance belongs to class $k$ by running the scores through the softmax function:\n",
        "\n",
        "$$\\hat{p}_k=\\sigma(\\boldsymbol{s}(\\boldsymbol{x}))_{k}=\\frac{e^{s_{k}(\\boldsymbol{x})}}{\\sum_{j=1}^{K}e^{s_{j}(\\boldsymbol{x})}}$$\n",
        "\n",
        "The softmax function computes the exponential of every score, then normalizes them (dividing by the sum of all the exponentials). The scores are generally called logits or log-odds (although they are actually unnormalized log-odds).\n",
        "\n",
        "- $K$ is the number of classes.\n",
        "- $\\boldsymbol{s}(\\boldsymbol{x})$ is a vector containing the scores of each class for the instance $\\boldsymbol{x}$.\n",
        "\n",
        "- $\\sigma(\\boldsymbol{s}(\\boldsymbol{x}))_{k}$ is the estimated probability that the instance $\\boldsymbol{x}$ belongs to class $k$ given the scores of each class for that instance.\n",
        "\n",
        "\n",
        "Just like the Logistic Regression classifier, the Softmax Regression classifier predicts the class with the highest estimated probability (which is simply the class with the highest score).\n",
        "\n",
        "$$\\hat{y}=\\text{arg}\\max\\limits_{k}\\sigma(\\boldsymbol{s}(\\boldsymbol{x}))_{k}=\\text{arg}\\max\\limits_{k}s_{k}(\\boldsymbol{x})=\\text{arg}\\max\\limits_{k}((\\boldsymbol{\\theta}^{(k)})^T \\boldsymbol{x})$$\n",
        "\n",
        "- The *argmax* operator returns the value of a variable that maximizes a function. In this equation, it returns the value of $k$ that maximizes the estimated probability $\\sigma(\\boldsymbol{s}(\\boldsymbol{x}))_{k}$.\n",
        "\n",
        "**Note**: The Softmax Regression classifier predicts only one class at a time\n",
        "(i.e., it is multiclass, not multioutput) so it should be used only with\n",
        "mutually exclusive classes such as different types of plants. You cannot use it to recognize multiple objects in one picture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VRTsqAsjjTE",
        "colab_type": "text"
      },
      "source": [
        "Let’s take a look at training. The objective is to have a model that estimates a high probability for the target class (and consequently a low probability for the other classes). Minimizing the cost function called the *cross-entropy*, should lead to this objective because it penalizes the model when it estimates\n",
        "a low probability for a target class. \n",
        "\n",
        "$$J(\\boldsymbol{\\Theta})= -\\frac{1}{m}\\sum_{i=1}^{m} \\sum_{k=1}^{K} y^{(i)}_klog(\\hat{p}_k^{(i)})$$\n",
        "\n",
        "- $y^{(i)}_k$ is the target probability that the $i^{\\text{th}}$ instance belongs to class $k$. In general, it is either equal to 1 or 0, depending on whether the instance belongs to the class or not.\n",
        "\n",
        "Cross entropy is frequently used to measure how well a set of estimated class probabilities match the target classes.\n",
        "\n",
        "Notice that when there are just two classes ($K = 2$), this cost function is equivalent to the Logistic Regression’s cost function (log loss).\n",
        "\n",
        "**Note**: Cross entropy originated from information theory. Suppose you want to efficiently transmit information about the weather every day. If there are eight options (sunny, rainy, etc.), you could encode each option using 3 bits since $2^3 = 8$. However, if you think it will be sunny almost every day, it would be much more efficient to code “sunny” on just one bit (0) and the other seven options on 4 bits (starting with a 1). Cross entropy measures the average number of bits you actually send per option. If your assumption about the weather is perfect, cross-entropy will just be equal to the entropy of the weather itself (i.e., its intrinsic unpredictability). But if your assumptions are wrong (e.g., if it rains often), cross-entropy will be greater by an amount called the [K–L divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence). The cross-entropy between two probability distributions $p$ and $q$ is defined as $H(p,q)=-\\sum_{x}p(x)log(q(x))$ (at least when the distributions are discrete). For more details, check out this [video](https://www.youtube.com/watch?v=ErfnhcEV1O8).\n",
        "\n",
        "The gradient vector of this cost function with regards to $\\boldsymbol{\\theta}^{(k)}$, $\\nabla_{\\boldsymbol{\\theta}^{(k)}}J(\\boldsymbol{\\Theta})$, can be easily calculated. We can compute the gradient vector for every class, then use Gradient Descent (or any other optimization algorithm) to find the parameter matrix $\\boldsymbol{\\Theta}$ that minimizes the cost function.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-59PCaQU2w5C",
        "colab_type": "text"
      },
      "source": [
        "Let’s use Softmax Regression to classify the iris flowers into all three classes. Scikit-Learn’s `LogisticRegression` uses one-versus-all by default when you train it on more than two classes, but you can set the `multi_class` hyperparameter to `\"multinomial\"` to switch it to Softmax Regression instead. You must also specify a solver that supports Softmax Regression, such as the `\"lbfgs\"` solver (see Scikit-Learn’s documentation for more details). It also applies $l_2$ regularization by default, which you can control using the hyperparameter `C`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnW0ntPHWjmi",
        "colab_type": "code",
        "outputId": "8292c550-33c4-4eb3-ee77-8878bb15c505",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "X = iris[\"data\"][:, (2, 3)] # petal length, petal width\n",
        "y = iris[\"target\"]\n",
        "\n",
        "softmax_reg = LogisticRegression(multi_class=\"multinomial\",solver=\"lbfgs\", C=10)\n",
        "softmax_reg.fit(X, y)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYA4eBgx3NCf",
        "colab_type": "text"
      },
      "source": [
        "If we find an iris with 5 cm long and 2 cm wide petals, we can ask\n",
        "our model to tell you what type of iris it is"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvkqJuQh3UL7",
        "colab_type": "code",
        "outputId": "813f0690-2894-45ac-d04f-71f4410dd8a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(softmax_reg.predict([[5, 2]]))\n",
        "print(softmax_reg.predict_proba([[5, 2]]))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2]\n",
            "[[6.38014896e-07 5.74929995e-02 9.42506362e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkAnzJw_3UWo",
        "colab_type": "text"
      },
      "source": [
        "The model answers Iris-Virginica (class 2) with 94.2% probability (or Iris-Versicolor with 5.8% probability).\n",
        "\n",
        "Figure 4-25 shows the resulting decision boundaries, represented by the background colors.\n",
        "\n",
        "![texto alternativo](https://i.ibb.co/k8SjSB7/softmax-regression-boundaries.png)\n",
        "\n",
        "Notice that the decision boundaries between any two classes are linear. The\n",
        "figure also shows the probabilities for the Iris-Versicolor class, represented by the curved lines (e.g., the line labeled with 0.450 represents the 45% probability boundary). Notice that the model can predict a class that has an estimated probability below 50%. For example, at the point where all decision boundaries meet, all classes have an equal estimated probability of 33%."
      ]
    }
  ]
}